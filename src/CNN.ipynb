{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# return BGR image with size [25,25,3]\n",
    "# done histogram equalization\n",
    "class TrafficSignDataset(Dataset):\n",
    "    def __init__(self, train):\n",
    "        self.img_list = []\n",
    "        self.label_list = []\n",
    "        if train:\n",
    "            for i in range(43):\n",
    "                path = f'./Dataset_2_Train/Train/{i}/'\n",
    "                for file in os.listdir(path):\n",
    "                    self.img_list.append(path + file)\n",
    "                    self.label_list.append(i)\n",
    "        else:\n",
    "            csv_file = open('./Dataset_2_Test/Test.csv')\n",
    "            reader = csv.reader(csv_file)\n",
    "            for item in reader:\n",
    "                if reader.line_num == 1:\n",
    "                    continue\n",
    "                self.label_list.append(int(item[6]))\n",
    "                self.img_list.append(f'./Dataset_2_Test/{item[7]}')
    "\n",
    "\n",
    "    def transform(self, path):\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, (32,32))\n",
    "        ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "        ycrcb[:, :, 0] = cv2.equalizeHist(ycrcb[:,:,0])\n",
    "        equalized = cv2.cvtColor(ycrcb, cv2.COLOR_YCrCb2RGB)\n",
    "        RGB = cv2.split(equalized)\n",
    "        np_res = np.stack(RGB, axis=0)\n",
    "        return torch.FloatTensor(np_res)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.transform(self.img_list[index]), self.label_list[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer_list = nn.ModuleList([])\n",
    "        self.layer_list.append(nn.Conv2d(n_channels, 64, 3, 1, 1))\n",
    "        self.layer_list.append(nn.BatchNorm2d(64))\n",
    "        self.layer_list.append(nn.MaxPool2d(3, 2, 1))\n",
    "        # 64*15*15\n",
    "        self.layer_list.append(nn.Conv2d(64, 128, 3, 1, 1))\n",
    "        self.layer_list.append(nn.BatchNorm2d(128))\n",
    "        # 128*15*15\n",
    "        self.layer_list.append(nn.MaxPool2d(3, 2, 1))\n",
    "        # 128*8*8\n",
    "        self.layer_list.append(nn.Conv2d(128, 256, 3, 1, 1))\n",
    "        self.layer_list.append(nn.BatchNorm2d(256))\n",
    "        # 256*8*8\n",
    "        self.layer_list.append(nn.Conv2d(256, 256, 3, 1, 1))\n",
    "        self.layer_list.append(nn.BatchNorm2d(256))\n",
    "        # 256*8*8\n",
    "        self.layer_list.append(nn.MaxPool2d(3, 2, 1))\n",
    "        # 256*5*5\n",
    "        self.layer_list.append(nn.Conv2d(256, 512, 3, 1, 1))\n",
    "        self.layer_list.append(nn.BatchNorm2d(512))\n",
    "        # 512*5*5\n",
    "        self.layer_list.append(nn.Conv2d(512, 512, 3, 1, 1))\n",
    "        self.layer_list.append(nn.BatchNorm2d(512))\n",
    "        # 512*5*5\n",
    "        self.layer_list.append(nn.MaxPool2d(3, 2, 1))\n",
    "        # 512*3*3\n",
    "        self.layer_list.append(nn.Conv2d(512, 512, 3, 1, 1))\n",
    "        self.layer_list.append(nn.BatchNorm2d(512))\n",
    "        # 512*3*3\n",
    "        self.layer_list.append(nn.Conv2d(512, 512, 3, 1, 1))\n",
    "        self.layer_list.append(nn.BatchNorm2d(512))\n",
    "        # 512*3*3\n",
    "        self.layer_list.append(nn.MaxPool2d(3, 2, 1))\n",
    "        self.linear_layer = nn.Linear(512, n_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layer_list:\n",
    "            if isinstance(layer, nn.BatchNorm2d):\n",
    "                # print(\"x:\", x.shape)\n",
    "                x = self.relu(layer(x))\n",
    "            else:\n",
    "                # print(\"x:\", x.shape)\n",
    "                x = layer(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        out = self.linear_layer(x)\n",
    "        return out\n",
    "\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def accuracy(predictions, targets):\n",
    "    cnt = 0\n",
    "    for idx in range(len(predictions)):\n",
    "        if np.argmax(predictions[idx]) == targets[idx]:\n",
    "            cnt += 1\n",
    "    return cnt / len(predictions)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import torch.optim as op\n",
    "\n",
    "default_lr = 1e-4\n",
    "max_epoch = 30\n",
    "eval_step = 3\n",
    "acc_list = []\n",
    "loss_list = []\n",
    "epoch_list = []\n",
    "\n",
    "train_set = TrafficSignDataset(train=True)\n",
    "test_set = TrafficSignDataset(train=False)\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n",
    "cnn = CNN(3, 43)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = op.Adam(params=cnn.parameters(), lr=default_lr)\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    print(epoch, \"/\", max_epoch, \"epoch finished\")\n",
    "    t = tqdm(train_loader)\n",
    "    t.set_description(\"epoch: %s\" % epoch)\n",
    "    for data in t:\n",
    "        inputs, labels = data\n",
    "        print(labels.dtype)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        t.set_postfix(loss=loss.item())\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_list.append(epoch + 1)\n",
    "    with torch.no_grad():\n",
    "        out = []\n",
    "        labels = []\n",
    "        for idx, data in enumerate(test_loader):\n",
    "            inputs, label = data\n",
    "            for l in label:\n",
    "                labels.append(l)\n",
    "            outputs = cnn(inputs)\n",
    "            for o in outputs.to_list():\n",
    "                out.append(o)\n",
    "            acc_list.append(accuracy(out, labels))\n",
    "\n",
    "plt.plot(epoch_list, acc_list, 's-', color='r', label='test_accuracy')\n",
    "plt.plot(epoch_list, loss_list, 's-', color='g', label='loss')\n",
    "plt.legend()\n",
    "plt.savefig(\"Result.png\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   0%|          | 0/1226 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 / 30 epoch finished\n",
      "torch.int64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   0%|          | 1/1226 [00:00<13:51,  1.47it/s, loss=4.2]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   0%|          | 2/1226 [00:01<15:36,  1.31it/s, loss=3.78]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   0%|          | 3/1226 [00:02<15:15,  1.34it/s, loss=3.62]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   0%|          | 4/1226 [00:02<14:52,  1.37it/s, loss=3.66]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   0%|          | 5/1226 [00:03<14:22,  1.42it/s, loss=3.28]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   0%|          | 6/1226 [00:04<13:57,  1.46it/s, loss=3.33]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   1%|          | 7/1226 [00:04<13:42,  1.48it/s, loss=3.46]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   1%|          | 8/1226 [00:05<13:30,  1.50it/s, loss=3.38]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   1%|          | 9/1226 [00:06<13:19,  1.52it/s, loss=3.48]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   1%|          | 10/1226 [00:06<13:15,  1.53it/s, loss=3.27]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   1%|          | 11/1226 [00:07<13:16,  1.52it/s, loss=3.21]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   1%|          | 12/1226 [00:08<13:09,  1.54it/s, loss=3.12]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   1%|          | 13/1226 [00:08<13:22,  1.51it/s, loss=3.26]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   1%|          | 14/1226 [00:09<13:12,  1.53it/s, loss=3.38]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   1%|          | 15/1226 [00:10<13:00,  1.55it/s, loss=2.95]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   1%|▏         | 16/1226 [00:10<13:13,  1.52it/s, loss=3.01]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   1%|▏         | 17/1226 [00:11<13:03,  1.54it/s, loss=3.23]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   1%|▏         | 18/1226 [00:12<13:08,  1.53it/s, loss=3.37]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   2%|▏         | 19/1226 [00:12<13:11,  1.52it/s, loss=2.68]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   2%|▏         | 20/1226 [00:13<13:12,  1.52it/s, loss=2.55]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   2%|▏         | 21/1226 [00:14<13:09,  1.53it/s, loss=2.83]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   2%|▏         | 22/1226 [00:14<13:35,  1.48it/s, loss=2.88]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   2%|▏         | 23/1226 [00:15<13:41,  1.46it/s, loss=2.75]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch: 0:   2%|▏         | 24/1226 [00:16<13:30,  1.48it/s, loss=2.86]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-de0fb2fad5d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/DeepLearning/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/DeepLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/DeepLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/DeepLearning/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/DeepLearning/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-735e69de1f2f>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-735e69de1f2f>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mycrcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2YCrCb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
